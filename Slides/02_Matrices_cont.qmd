---
title: "Matrices II"
subtitle: Linear Algebra and Programming Skills
author: "Dr Jon Shiach"
format:
  revealjs:
    slide-level: 3
    transition: slide
    navigation-mode: vertical
    theme: [default, custom.scss]
    controls-layout: bottom-right
    controls-tutorial: true
    smaller: true
    presentation-h2-font-size: 0.5em
---

# Determinants

A **determinant** is a scalar value that is calculated using the elements of a square matrix (non-square matrices do not have a determinant). 

Consider the system of two linear equations

$$ \begin{align*}
    ax + by &= e, \\
    cx + dy &= f.
\end{align*} $$

The solution for $x$ and $y$ is

$$ \begin{align*}
    x &= \frac{de - bf}{ad - bc}, &
    y &= \frac{af - ce}{ad - bc}.
\end{align*} $$

The denominators in the solutions to $x$ and $y$ are both $a d - b c$, so if this value is zero then the system of equations does not have a solution. 

# Determinants cont.

If we write the system using matrices

$$ \begin{align*}
    \begin{array}{rl}
        ax + by &= e, \\
        cx + dy &= f.
    \end{array}
    \quad \implies \quad
    \begin{pmatrix} a & b \\ c & d \end{pmatrix}
    \begin{pmatrix} x \\ y \end{pmatrix} =
    \begin{pmatrix} e \\ f \end{pmatrix} 
\end{align*} $$

then $ad - bc$ is known as the **determinant** of the $2 \times 2$ matrix $\begin{pmatrix} a & b \\ c & d \end{pmatrix}$

The determinant of a square matrix $A$ is denoted by $\det(A)$ or $|A|$ and is a scalar value that can be computed from the values of its elements.

# Determinant of a $2 \times 2$ Matrix

The determinant of the $2 \times 2$ matrix $\begin{pmatrix}a & b \\ c & d \end{pmatrix}$ is

$$ \det \begin{pmatrix} a & b \\ c & d \end{pmatrix} =
\begin{vmatrix} a & b \\ c & d \end{vmatrix} = ad - bc. $$

I.e., the product of the elements on the main diagonal minus the product of the other two elements. 

# Activity

Calculate the following determinants

\(i) &emsp; $\begin{vmatrix} 5 & 2 \\ 3 & 4 \end{vmatrix}$; &emsp;
(ii) &emsp; $\det \begin{pmatrix} a & b \\ ka & kb \end{pmatrix}$; &emsp;
(iii) &emsp; $\begin{vmatrix} 2-\lambda & 3 \\ 5 & 6 - \lambda \end{vmatrix}$

:::{.fragment .fade-up}
**Solution**

\(i) &emsp; $\det\begin{pmatrix} 5 & 2 \\ 3 & 4 \end{pmatrix} = 14$; &emsp;

\(ii) &emsp; $\det \begin{pmatrix} a & b \\ ka & kb \end{pmatrix} = 0$; &emsp;

\(iii) &emsp; $\det \begin{pmatrix} 2-\lambda & 3 \\ 5 & 6 - \lambda \end{pmatrix} = \lambda^2 - 8 \lambda - 3$
:::

# Minors

The **minor** of an element of an $n \times n$ square matrix is denoted by $M_{ij}$ and is the determinant of the $(n-1) \times (n-1)$ square matrix that is formed by removing row $i$ and column $j$ from $A$.

For example, given the matrix $A$

$$ A = \begin{pmatrix}
    a_{11} & a_{12} & a_{13} \\
    a_{21} & a_{22} & a_{23} \\
    a_{31} & a_{32} & a_{33}
\end{pmatrix}, $$

then the minor $M_{21}$ is the determinant of the matrix $A$ with row 2 and column 1 removed

$$ M_{21} = \begin{vmatrix}
    {\color{lightgray} \square} & a_{12} & a_{13} \\
    {\color{lightgray} \square} & {\color{lightgray} \square} & {\color{lightgray} \square} \\
    {\color{lightgray} \square} & a_{32} & a_{33}
\end{vmatrix}
= \begin{vmatrix}
    a_{12} & a_{13} \\
    a_{32} & a_{33}
\end{vmatrix}
= a_{12}a_{33} - a_{13}a_{32}. $$

# Cofactors

The **cofactor** of an element of a square matrix is denoted by $C_{ij}$ and is defined by

$$ C_{ij} = (-1)^{i+j}M_{ij}. $$

The $(-1)^{i+j}$ term is positive when $i + j$ is even and negative when $i + j$ is odd which results in the following pattern of signs

$$ \begin{pmatrix}
        + & - & + & \cdots \\
        - & + & - & \cdots \\
        + & - & + & \cdots \\
        \vdots & \vdots & \vdots & \ddots
\end{pmatrix}. $$

# Determinant of an $n \times n$ matrix

The determinant of an $n\times n$ matrix $A$ is defined by

$$ \det(A) = \sum_{i=1}^n a_{ik} C_{ik} = \sum_{j=1}^n a_{kj} C_{kj}, $$

for some fixed value in the range $1 \leq k \leq n$ which represents a single row or column of $A$.

This equation allows us to express the determinant of an $n \times n$ matrix in terms of determinants of $(n-1) \times (n-1)$ matrices. 

We then apply the formula again to the sub-matrices continuing until we have $2\times 2$ matrices.

# Determinant of an $n \times n$ matrix cont.

For example, to calculate $\det(A)$ where $A = \begin{pmatrix} a & b & c \\ d & e & f \\ g & h & i \end{pmatrix}$ we can expand across row 1

$$ \begin{align*}
    \det(A) &= a C_{11} + b C_{12} + cC_{13} \\
    &= (-1)^{(1+1)} a \begin{vmatrix} e & f \\ h & i \end{vmatrix}
    + (-1)^{(1+2)} b \begin{vmatrix}d & f \\ g & i \end{vmatrix}
    + (-1)^{(1+3)} c \begin{vmatrix}d & e \\ g & h \end{vmatrix} \\
    &= a(ei - fh) - b(di - fg) + c(dh - eg) \\
    &= aei - afh - bdi + bfg + cdh - ceg.
\end{align*} $$

We could also had chosen to expand along column 2

$$ \begin{align*}
    \det(A) &= b C_{12} + e C_{22} + h C_{32} \\
    &= (-1)^{(1+2)} b\begin{vmatrix} d & f \\ g & i \end{vmatrix}
    + (-1)^{(2+2)}e \begin{vmatrix} a & c \\ g & i \end{vmatrix}
    + (-1)^{(3+2)}h \begin{vmatrix} a & c \\ d & f \end{vmatrix} \\
    &= -b(di-fg) + e(ai-cg) - h(af-cd) \\
    &= -bdi + bfg + aei - ceg - afh + cdh.
\end{align*} $$

Note that either approach gives the same result.

# Activity

Calculate the determinants of

\(i) &emsp; $A = \begin{pmatrix} 1 & 0 & 4 \\ 2 & 5 & 6 \\ 4 & 5 & 2 \end{pmatrix}$; &emsp;
(ii) &emsp; $B = \begin{pmatrix} 1 & -1 & 4 & 3 \\ 2 & 0 & 5 & -3 \\ 1 & 2 & 4 & 5 \\ 2 & 0 & -2 & 4 \end{pmatrix}$

. . .

**Solutions**

\(i) &emsp; $-60$; &emsp; (ii) &emsp; $280$

# Properties of Determinants

Determinants have the following properties:

- $\det(AB) = \det(A)\det(B)$
- $\det(A) = \det(A^\mathsf{T})$
- If a matrix has a row or column with all zero elements then its determinant is zero
- Interchanging any two rows of a matrix changes the sign of the determinant
- If all elements in a row are multiplied by a scalar $k$ then the determinant is also multiplied by $k$
- If one row of a matrix is a multiple of another row then the matrix has a determinant of zero
- The value of a determinant is unchanged by adding a multiple of one row to another row

# Inverse Matrix

The inverse of a matrix $A$, is denoted as $A^{-1}$ and defined by

$$AA^{-1} = A^{-1}A = I$$

For example, given the matrix $A = \begin{pmatrix} 1 & 1 \\ 1 & 2 \end{pmatrix}$ then its inverse is $A^{-1} = \begin{pmatrix} 2 & -1 \\ -1 & 1 \end{pmatrix}$ since

$$ \begin{align*}
    AA^{-1} = \begin{pmatrix} 2 & -1 \\ -1 & 1 \end{pmatrix}\begin{pmatrix} 1 & 1 \\ 1 & 2 \end{pmatrix} = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} = I, \\
    A^{-1}A = \begin{pmatrix} 1 & 1 \\ 1 & 2 \end{pmatrix}\begin{pmatrix} 2 & -1 \\ -1 & 1 \end{pmatrix} = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} = I
\end{align*}$$

# Inverse Matrix cont.

Note

- Not all square matrices have an inverse
- If a matrix does not have an inverse it has a determinant of zero and is said to be **singular**
- If a matrix has an inverse it has a non-zero determinant and it is said to be **non-singular** or **invertible**
- An inverse of a square matrix is unique

If $A$ and $B$ are invertible matrices then the following properties are satisfied

- $(AB)^{-1} = B^{-1}A^{-1}$
- $(A^\mathsf{T})^{-1} = (A^{-1})^\mathsf{T}$
- $(A^m)^{-1} = (A^{-1})^m$ &emsp; for all positive integers $m$

# The Adjoint-Determinant Formula

The inverse of a non-singular square matrix $A$ can be calculated using the adjoint-determinant formula

$$ A^{-1} = \frac{\operatorname{adj}(A)}{\det(A)},$$

where $\operatorname{adj}(A)$ is the **adjoint** of $A$ which is the transpose of the matrix of co-factors

$$ \begin{align*}
    \operatorname{adj}(A) &= C^\mathsf{T}.
\end{align*} $$

# Inverse Matrix Example

Calculate the inverse of

$$ A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}. $$

Here $\det(A) = -2$ which is non-zero so we know that an inverse exists for $A$ 

Next we calculate the adjoint

$$ \begin{align*}
    \operatorname{adj}(A) =
    \begin{pmatrix} 4 & -3 \\ -2 & 1 \end{pmatrix}^\mathsf{T}
    =
    \begin{pmatrix} 4 & -2 \\ -3 & 1 \end{pmatrix}.
\end{align*} $$

Using the adjoint-determinant formula, the inverse of $A$ is

$$ \begin{align*}
    A^{-1} &= \frac{1}{-2}\begin{pmatrix} 4 & -2 \\ -3 & 1 \end{pmatrix}
    = \begin{pmatrix} -2 & 1 \\ \frac{3}{2} & -\frac{1}{2} \end{pmatrix}.
\end{align*} $$

---

$$ \begin{align*}
    A^{-1} &= \begin{pmatrix} -2 & 1 \\ \frac{3}{2} & -\frac{1}{2} \end{pmatrix}.
\end{align*} $$

We can check that this is the correct inverse by calculating $AA^{-1}$

$$ \begin{align*}
    AA^{-1} &=
    \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}
    \begin{pmatrix} -2 & 1 \\ \frac{3}{2} & -\frac{1}{2} \end{pmatrix}
    =
    \begin{pmatrix} -2 + 3 & 1 - 1 \\ -6 + 6 & 3 - 2 \end{pmatrix}
    =
    \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}.
\end{align*} $$

So we know our inverse matrix is correct.

# Activity

Calculate the inverses of the following matrices if they exist:

\(i) &emsp; $A = \begin{pmatrix}1 & 0 \\ 3 & 2\end{pmatrix}$; &emsp;
\(ii) &emsp; $B = \begin{pmatrix} 1 & 2 & 0 \\ -2 & 1 & 1 \\ 1 & 0 & 3 \end{pmatrix}$; &emsp;
\(iii) &emsp; $C = \begin{pmatrix}1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{pmatrix}$

:::{.fragment}
**Solution**

\(i) &emsp; $A^{-1} = \dfrac{1}{2}\begin{pmatrix} 2 & 0 \\ -3 & 1\end{pmatrix}$

\(ii) &emsp; $B^{-1}  = \dfrac{1}{17}\begin{pmatrix} 3 & -6 & 2 \\ 7 & 3 & -1 \\ -1 & 2 & 5 \end{pmatrix}$

\(iii) &emsp; $C$ is singular and does not have an inverse.
:::

# Matrix Algebra

Consider the algebraic equation

$$ c x + a = b, $$

where $a,b,c \in \mathbb{R}$ then its easy to see that the solution is

$$ x = \frac{1}{c}(b - a). $$

However, the equivalent matrix equation

$$ C X + A = B, $$

where $A, B, C$ are $n \times n$ matrices.

We cannot divide by a matrix so how can we solve for $X$?

---

We can't divide by a matrix but we can multiply by the inverse

$$ \begin{align*}
    C X + A &= B \\
    CX &= B - A \\
    C^{-1} C X &= C^{-1} (B - A) \\
    I X &= C^{-1}(B - A) \\
    X &= C^{-1}(B - A).
\end{align*} $$

Note 

- For a solution to exist $C$ must be invertible
- Matrix multiplication is non-commutative so we must multiply both sides of the equation by the inverse on the same side

# Matrix Algebra Example

Solve $\begin{pmatrix} 4 & 1 \\ 2 & 5 \end{pmatrix} X - \begin{pmatrix} 5 & -3 \\ 2 & 4 \end{pmatrix} = \begin{pmatrix} 1 & 1 \\ 3 & 2 \end{pmatrix}$ for $X$

**Solution**

$$ \begin{align*}
    \begin{pmatrix} 4 & 1 \\ 2 & 5 \end{pmatrix} X -
    \begin{pmatrix} 5 & -3 \\ 2 & 4 \end{pmatrix}
    &=
    \begin{pmatrix} 1 & 1 \\ 3 & 2 \end{pmatrix} \\
    \begin{pmatrix} 4 & 1 \\ 2 & 5 \end{pmatrix} X
    &=
    \begin{pmatrix} 1 & 1 \\ 3 & 2 \end{pmatrix} +
    \begin{pmatrix} 5 & -3 \\ 2 & 4 \end{pmatrix} \\
    X &=
    \begin{pmatrix} 4 & 1 \\ 2 & 5 \end{pmatrix}^{-1}
    \begin{pmatrix} 6 & -2 \\ 5 & 6 \end{pmatrix} \\
    &=
    \frac{1}{18} \begin{pmatrix} 5 & -1 \\ -2 & 4 \end{pmatrix}
    \begin{pmatrix} 6 & -2 \\ 5 & 6 \end{pmatrix} \\
    &= \begin{pmatrix} 25 & -16 \\ 8 & 28 \end{pmatrix}
\end{align*} $$

# Matrix Algebra Activity

Solve the following matrix equation for $X$

$$X^2 = \begin{pmatrix} 4 & 3 \\ 0 & 1 \end{pmatrix}$$

Hint: Let $X = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$ and solve for $a$, $b$, $c$ and $d$

## Solution

Let $X = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$ then

$$ \begin{align*}
    X^2 &=
    \begin{pmatrix} a & b \\ c & d \end{pmatrix}
    \begin{pmatrix} a & b \\ c & d \end{pmatrix}
    =
    \begin{pmatrix} a^2 + bc & b(a + d) \\ c(a + d) & bc + d^2 \end{pmatrix}
    =
    \begin{pmatrix} 4 & 3 \\ 0 & 1 \end{pmatrix}
\end{align*} $$

:::{.fragment}
Taking the element in row 2 column 1 we have $c(a+d)=0$ so either $c=0$ or $a + d = 0$
:::

:::{.fragment}
When $c = 0$

$$ \begin{align*}
    X^2 = \begin{pmatrix} a^2 & b(a + d) \\ 0 & d^2 \end{pmatrix}
    =
    \begin{pmatrix} 4 & 3 \\ 0 & 1 \end{pmatrix}
\end{align*} $$

so $a = \pm 2$ and $d = \pm 1$ and solving top-right element for $b$ gives $b = \dfrac{3}{a + b}$
:::

---

$$X = \begin{pmatrix} a & \dfrac{3}{a + b} \\ c & d \end{pmatrix}$$

Since when $c=0$, $a = \pm 2$ and $d = \pm 1$ we have four possible solutions

$$ \begin{align*}
    a &= 2, d = 1: &
    X &= 
    \begin{pmatrix} 2 & 1 \\ 0 & 1 \end{pmatrix}, \\
    a &= 2, d = -1: &
    X &=
    \begin{pmatrix} 2 & 3 \\ 0 & -1 \end{pmatrix}, \\
    a &= -2, d = 1: &
    X &=
    \begin{pmatrix} -2 & -3 \\ 0 & 1 \end{pmatrix}, \\
    a &= -2, d = -1: &
    X &=
    \begin{pmatrix} -2 & -1 \\ 0 &  -1 \end{pmatrix}.
\end{align*} $$

---

$$ \begin{align*}
    X^2 = \begin{pmatrix} a^2 + bc & b(a + d) \\ c(a + d) & bc + d^2 \end{pmatrix}
    =
    \begin{pmatrix} 4 & 3 \\ 0 & 1 \end{pmatrix}
\end{align*} $$

When $a + d = 0$, the element in row 1 column 2 gives

$$ \begin{align*}
    b(a + d) &= 3 \\
    0 &\neq 3,
\end{align*} $$

which is a contradiction so $a + d=0$ yields no solutions.
