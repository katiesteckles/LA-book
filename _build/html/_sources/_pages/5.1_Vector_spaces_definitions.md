(vector-spaces-definitions-section)=

# Definitions

```{prf:definition} Field
:label: field-definition

A **field** is a set $F$ together with two *binary operations*, which each combine two elements of $F$, called *addition* and *multiplication*. If $a,b \in F$ then addition is written as $a + b$, and multiplication is written as $a \times b$.
```

The classic example of a field is a set of numbers, e.g. the real numbers $\mathbb{R}$, which will suffice for what we're doing here. However, a field can be any set of objects for which the above definition is satisfied, and you may meet other examples of fields later in your studies.

```{prf:definition} Vector space
:label: vector-space-definition

A **vector space** over a field $F$ is a non-empty set $V$ of objects called vectors, on which the binary operations below are defined

- **addition** $(+)$: $V \times V \to V$. Given two elements $u, v \in V$ we can 'add' them together to obtain another element $u + v \in V$.
- **scalar multiplication** $(\cdot)$: $F \times V \to V$. Given $\alpha \in F$ and $u \in V$ we can 'multiply' $u$ by $\alpha$ to obtain another element $\alpha \cdot u \in V$.
```

For example, a field could be the set of all real numbers $\mathbb{R}$ and the vector set could be the set of all vectors (as we have previously used the word) in $\mathbb{R}^3$ - tuples with three entries, each of which is an element of $\mathbb{R}$. Then we can define a vector space consisting of that set of vectors over that field. We can add two vectors together, and multiply a vector by a scalar.

We use the word 'over' to indicate that the set of vectors is combined with the scalars from the given field by scalar multiplication: the set of vectors $V$, over the field $F$, is a vector space. It may be that the vectors themselves are made from elements of the field, combined in some way (e.g. entries in a tuple, or coefficients in a polynomial) - and this is often the case, since then scalar multiplication involves multiplying by other elements of the field, and this is a defined operation within the field.

Not every set of objects can be called a vector space. To be a vector space, we need the set $V$ to satisfy a particular set of axioms:

```{index} Vector spaces ; axioms
```

```{prf:axiom} Axioms of a vector space
:label: vector-space-axioms

$V$ is a vector space (over $F$) if all of the following axioms are satisfied, for all $u, v, w \in V$ and $\alpha, \beta \in F$:

- **A1**: Associativity of vector addition: $u + (v + w) = (u + v) + w$
- **A2**: Commutativity of vector addition: $u + v = v + u$
- **A3**: Identity element of vector addition: there exists an element $\mathbf{0} \in V$ such that $u + \mathbf{0} = u$ for all $v \in V$
- **A4**: Additive inverse: For every $u \in V$ there exists an element $- v \in V$, called the **additive inverse**, such that $u + (- u) = \mathbf{0}$
- **M1**: Associativity of scalar multiplication: $\alpha(\beta u) = (\alpha \beta) u$
- **M2**: Identity element of scalar multiplication: there exists an element $1 \in F$, called the **multiplicative identity**, such that $1 u = u$
- **M3**: Distributivity of scalar multiplication with respect to vector addition: $\alpha(u + v) = \alpha u + \alpha v$
- **M4**: Distributivity of scalar multiplication with respect to addition: $(\alpha + \beta)u = \alpha u + \beta u$
```

The first four axioms are concerned with addition, and the next four axioms are concerned with scalar multiplication. When the scalars are real numbers, e.g., $F = \mathbb{R}$, we call $V$ a *'real vector space'*, or a *'vector space over the field of real numbers'*. When the scalars are complex numbers, e.g., $F=\mathbb{C}$, we call $V$ a *'complex vector space'*.

From the axioms, we can derive some basic properties for multiplication by scalars in a vector space.

```{prf:theorem} Properties of vector spaces
:label: properties-of-vector-spaces-theorem

Let $V$ be a vector space over $F$ and $u \in V,\alpha\in F$. Then the following hold:

- $\alpha \cdot 0 = 0$;
- $0 \cdot u = 0$;
- if $\alpha u = 0$ then either $\alpha = 0$ or $u = 0$;
- $-(\alpha u) = (-\alpha)u = \alpha (-u)$.
```

The name *'vector space'* comes from the fact that vectors are a natural object we can use to create such spaces. Indeed, Euclidean space $\mathbb{R}^n$, as introduced in [Vectors](vectors-chapter), is a vector space over $F=\mathbb{R}$ consisting of vectors of $n$ coordinates. Addition and scalar multiplication, in the sense of a vector space, for $\mathbb{R}^n$ are as given in {prf:ref}`vector addition<vector-addition-definition>` and {prf:ref}`scalar multiplication<scalar-multiplication-of-a-vector-definition>` respectively.

Euclidean space, with vectors of coordinates, is often the first example of a vector space that a student meets. But on its own, it doesn't quite demonstrate the power behind this construction. The real motivation for the study of vector spaces comes from the fact that many more abstract sets, like the set of differentiable functions or the set of matrices, can be considered as vector spaces. Everything that we learn about vector spaces can be then applied to any set which satisfies the definition of a vector space. This means that the set of $m\times n$ matrices with matrix addition and scalar multiplication, or the set of all polynomials of degree at most $n$, in some sense, behave in a very similar fashion to Euclidean space.

```{prf:example}
:label: real-numbers-vector-space-example

(i) &emsp; Show that the set of real numbers $\mathbb{R}$, over itself, is a vector space.

(ii) &emsp; Consider the set of all polynomials of degree at most $n$ with real coefficients, which we denote $P_n(\mathbb{R})$:

$$ \begin{align*}
    p(x) := a_0x^0 + a_1x^1 + a_2x^2 + \cdots + a_nx^n = \sum_{i=0}^n a_ix^i,
\end{align*} $$

where $a_i \in \mathbb{R}$ and $x$ is some variable. Show that $P(\mathbb{R}_n)$, over the field $\mathbb{R}$, is a vector space.

```{dropdown} Solution

(i) &emsp; We need to check that all the axioms of vector spaces are satisfied. Here $V = \mathbb{R}$ and $F = \mathbb{R}$, so let $u, v, w \in \mathbb{R}$ and $\alpha, \beta \in \mathbb{R}$.

- A1: $u + (v + w) = (u + v) + w \quad \checkmark$
- A2: $u + v = v + u \quad \checkmark$
- A3: $u + 0 = u \quad \checkmark$ (i.e., 0 is the identity element of addition)
- A4: $u + (-u) = 0 \quad \checkmark$ (i.e., the negative of any number is the additive inverse)
- M1: $\alpha(\beta u) = (\alpha \beta) u \quad \checkmark$
- M2: $1 u = u \quad \checkmark$ (i.e., 1 is the multiplicative identity of all numbers)
- M3: $\alpha(u + v) = \alpha u + \alpha v \quad \checkmark$
- M4: $(\alpha + \beta) u = \alpha u + \beta u \quad \checkmark$

(ii) &emsp; Let $u(x), v(x), w(x) \in P_n(\mathbb{R})$ where $u_i, v_i, w_i \in \mathbb{R}$ are the coefficients for $u(x)$, $v(x)$ and $w(x)$ respectively and $k\in \mathbb{R}$ is some scalar. Then we define:

- Vector addition:

$$ \begin{align*}
    u(x) + v(x) &= (u_0 + v_0)x^0 + (u_1 + v_1)x^1 + \cdots + (u_n + v_n)x^n \\
    &= \sum_{i=0}^n (u_i + v_i)x^i.
\end{align*} $$

- Scalar multiplication:

$$ \begin{align*}
    k \cdot u(x) &= ku_0x^0 + ku_1x^1 + \cdots + ku_nx^n \\
    &= \sum_{i=0}^n ku_ix^i.
\end{align*} $$

- The additive identity element is the zero polynomial

$$ \begin{align*}
    0 = 0x^0 + 0x^1 + \cdots + 0x^n.
\end{align*} $$

- The additive inverse to a polynomial $u(x)$ is

$$ \begin{align*}
    -u(x) &= (-u_0)x^0 + (-u_1)x^2 + \cdots + (-u_n)x^n \\
    &= \sum_{i=0}^n (-u_i)x^i \\
    &= -\sum_{i=0}^n u_ix^i.
\end{align*} $$

Checking the that axioms of vector spaces are satisfied

- A1: Associativity of addition
  
$$ \begin{align*}
    u(x) + (v(x) + w(x)) &= \displaystyle \sum_{i=0}^n (u_i + (v_i + w_i))x^i \\
    &= \displaystyle \sum_{i=0}^n ((u_i + v_i) + w_i)x^i \\
    &= (u(x) + v(x)) + w(x) \quad \checkmark
\end{align*} $$

- A2: Commutativity of addition
  
$$ \begin{align*}
    u(x) + v(x) &= \displaystyle \sum_{i=0}^n (u_i + v_i)x^i \\
    &= \displaystyle \sum_{i=0}^n (v_i + u_i)x^i \\
    &= v(x) + u(x) \quad \checkmark
\end{align*} $$

- A3: Identity element for addition
  
$$ \begin{align*}
    u(x) + 0 &= \displaystyle \sum_{i=0}^n (u_i + 0)x^i \\
    &= \displaystyle \sum_{i=0}^n u_ix^i \\
    &= u(x) \quad \checkmark
\end{align*} $$

- A4: Inverse element for addition
  
$$ \begin{align*}
    u(x) + (-u(x)) &= \displaystyle \sum_{i=0}^n(u_i + (-u_i)) x^i \\
    &= 0 \quad \checkmark
\end{align*} $$

- M1: Associativity of scalar multiplication
  
$$ \begin{align*}
    \alpha(\beta u(x)) &= \alpha \displaystyle \sum_{i=0}^n \beta u_i x^i \\
    &= \alpha \beta \displaystyle \sum_{i=0}^n u_i x^i \\
    &= (\alpha \beta) u(x) \quad \checkmark
\end{align*} $$

- M2: Identity element for scalar multiplication
  
$$ \begin{align*}
    1 \cdot u(x) &= \displaystyle \sum_{i=0}^n 1 u_i x^i \\
    &= \displaystyle \sum_{i=0}^n u_i x^i \\
    &= u(x) \quad \checkmark
\end{align*} $$

- M3: Distributivity of scalar multiplication
  
$$ \begin{align*}
    \alpha (u(x) + v(x)) &= \alpha \sum_{i=0}^n (u_i + v_i) x^i \\
    &= \alpha \sum_{i=0}^n u_i x^i + \alpha \sum_{i=0}^n v_i x^i \\
    &= \alpha u(x) + \alpha v(x) \quad \checkmark
\end{align*} $$

- M4: Distributivity of scalar multiplication over addition

$$ \begin{align*}
    (\alpha + \beta) u(x) &= (\alpha + \beta) \displaystyle \sum_{i=0}^n u_i x^i \\
    &= \alpha \displaystyle \sum_{i=0}^n u_i x^i + \beta \displaystyle \sum_{i=0}^n u_i x^i \\
    &= \alpha u(x) + \beta u(x) \quad \checkmark
\end{align*} $$
```

---

## Examples of non-vector spaces

Not all sets are vector spaces. For example, consider the set of integers $\mathbb{Z}$ over the field $F=\mathbb{R}$. It is easy to show that the {prf:ref}`axioms A1 to A4<vector-space-axioms>` are satisfied for the set of integers, which can be added together using standard integer addition.

The problem comes when one tries to define scalar multiplication - from the {prf:ref}`definition of scalar multiplication<vector-space-definition>`, we need a binary operation $\mathbb{R} \times \mathbb{Z} \to \mathbb{Z}$. This would mean that for all $u \in \mathbb{Z}$ and $\alpha \in \mathbb{R}$, $\alpha x\in \mathbb{Z}$.

However, this is not always the case - for example, when $u=1$ and $\alpha = \frac{1}{2}$, we have $\frac{1}{2} \cdot 1 = \frac{1}{2} \notin \mathbb{Z}$. This is an example of proof by counterexample: we just need to show one instance where the axioms are not satisfied to prove that we do not have a vector space.

```{prf:example}
:label: non-vector-space-example

Show that the following are not vector spaces:

(i) &emsp; The set of all positive real numbers, $\mathbb{R}_+$, over itself;

(ii) &emsp; $V$ is defined to be the set of points on the parabola $y=x^2$ in $\mathbb{R}^2$, i.e., all the points in $\mathbb{R}^2$ that can be written as a pair $(x, x^2)$, over the field $\mathbb{R}$. Addition of vectors here is defined pointwise, so $(x, x^2) + (y, y^2) = (x+y, x^2 + y^2)$.

```{dropdown} Solution

(i) &emsp; We do not have an identity element for addition, since $0 \notin \mathbb{R}_+$ so axiom A3 is not satisfied. Also, by axiom A4, if $u, v \in \mathbb{R}_+$ are two positive real numbers then $x + y > 0$ so no additive inverse exists.

(ii) &emsp; If we consider the vector $(1, 1)$, its additive inverse under vector addition as defined would be $(-1, -1) \notin V$, so $V$ is not a vector space.
```

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/FBjz56gTkA4?si=QGstB_gRQBMAN_aQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>