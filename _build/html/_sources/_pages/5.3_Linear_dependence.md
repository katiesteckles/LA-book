(linear-dependence-section)=

```{index} Linear dependence
```

# Linear dependence

When working in a vector space, we can add together scalar multiples of vectors to form a **linear combination**. An important concept in linear algebra is that of whether a specific vector from a set of vectors can be expressed as a linear combination of the other vectors in the set.

If it can, we say that the vector is **linearly dependent** upon the other vectors. Linear dependence can help identify redundant or superfluous vectors within a set, and provides insight into the wider structure of a vector space.

```{prf:definition} Linear dependence
:label: linear-dependence-definition

Let $v_1, v_2, \ldots, v_n \in V$ and consider the equation

$$ \alpha_1 v_1 + \alpha_2 v_2 + \cdots + \alpha_n v_n = 0, $$(linear-dependence-equation)

where $\alpha \in F$. The objects $v_1, v_2, \ldots, v_n \in V$ are said to be **linearly independent over $F$** if the only solution to the above equation is when all of the $\alpha_i$ values are zero (called the trivial solution).

If the above equation is satisfied where $\alpha_i \neq 0$ for $1 \leq i \leq n$, then $v_1, v_2, \ldots, v_n \in V$ are said to be **linearly dependent over $F$**.
```

Another way to think about linear independence is that a set of vectors is **linearly independent** if none of the vectors in the set can be represented as a linear combination of the other vectors in the same set. For example, consider the set of matrices

$$ \begin{align*}
    A &= \begin{pmatrix} 1 & 1 \\ 0 & 2 \end{pmatrix}, &
    B &= \begin{pmatrix} -1 & -1 \\ 0 & -2 \end{pmatrix}, &
    C &= \begin{pmatrix} -4 & 0 \\ 0 & -8 \end{pmatrix},
\end{align*} $$

Is this set linearly independent over $\mathbb{R}$? We can see by inspection that $B = -A$, so therefore $A$, $B$ and $C$ are linearly dependent, since we can write:

$$ 1A + 1B + 0C = \mathbf{0}_{2\times 2}. $$

So if any two members of a set are scalar multiples of each other, then the set is linearly dependent, because we can choose $\alpha_i$ values to satisfy equation {eq}`linear-dependence-equation`.

Note that linear dependence and linear independence are properties of a set, not of a particular vector: one vector cannot be linearly independent, as this property is defined relative to the other vectors in the set.

<iframe width="560" height="315" src="https://www.youtube.com/embed/GMMOeRIEbrc?si=q8Hx4v23EJaD_sYE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

```{prf:example}
:label: linear-dependence-equation

Determine whether the following sets are linearly dependent:

(i) &emsp; $(1, 0, 2), (2, 1, 3),(-3, -4, -2) \in \mathbb{R}^3$ over $\mathbb{R}$

(ii) &emsp; $u = x^2 + x + 1$, $v = x - 1$ and $w = x^2 - 1 \in P(\mathbb{R})$ over $\mathbb{R}$

```{dropdown} Solution

(i) &emsp; Let $\alpha_1, \alpha_2, \alpha_3 \in \mathbb{R}$. Then equation {eq}`linear-dependence-equation` becomes

$$ \begin{align*}
    \alpha_1 \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix} +
    \alpha_2 \begin{pmatrix} 2 \\ 1 \\ 3 \end{pmatrix} +
    \alpha_3 \begin{pmatrix} -3 \\ -4 \\ -2 \end{pmatrix} &=
    \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}.
\end{align*} $$

This holds if and only if

$$ \begin{align*}
    \alpha_1 + 2\alpha_2 - 3\alpha_3 &= 0, \\
    \alpha_2 - 4\alpha_3 &= 0, \\
    2\alpha_3 + 3\alpha_2 - 2\alpha_3 &= 0.
\end{align*} $$

Solving this homogeneous system using Gauss-Jordan elimination

$$ \begin{align*}
    & \left( \begin{array}{ccc}
        1 & 2 & -3\\
        0 & 1 & -4\\
        2 & 3 & -2
    \end{array} \right)
    \\ \\
    R_3 - 2R_1 \longrightarrow
    &\left( \begin{array}{ccc}
        1 & 2 & -3\\
        0 & 1 & -4\\
        0 & -1 & 4
    \end{array} \right)
	\\ \\
    \begin{matrix} R_1 - 2R_2 \\ \\ R_3 + R_2 \end{matrix} \longrightarrow
    &\left( \begin{array}{ccc}
        1 & 0 & 5\\
        0 & 1 & -4\\
        0 & 0 & 0
    \end{array} \right)
\end{align*} $$

Here $\alpha_3$ is a free variable, so let $\alpha_3 = r$. Then $\alpha_1 = -5r$ and $\alpha_2 = 4r$. These vectors are therefore linearly dependent, i.e., if $r = 1$, then $\alpha_1 = -5$ and $\alpha_2 = 4$, meaning we have:

$$ \begin{align*}
    - 5 \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix}
    + 4 \begin{pmatrix} 2 \\ 1 \\ 3 \end{pmatrix}
    + \begin{pmatrix} -3 \\ -4 \\ -2 \end{pmatrix} =
    \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}.
\end{align*} $$

(ii) &emsp; Let $\alpha_1, \alpha_2, \alpha_3 \in \mathbb{R}$. Then we need to ascertain when

$$ \begin{align*}
    \alpha_1 u + \alpha_2 v + \alpha_3 w = 0.
\end{align*} $$

Substituting in the expressions for $u$, $v$ and $w$:

$$ \begin{align*}
    \alpha_1 (x^2 + x + 1) + \alpha_2 (x - 1) + \alpha_3 (x^2 - 1) &= 0 \\ \\
    (\alpha_1 + \alpha_3)x^2 + (\alpha_1 + \alpha_2)x + (\alpha_1 - \alpha_2 - \alpha_3)x^0 &= 0.
\end{align*} $$

For a polynomial to be equal to zero, the coefficients of $x^i$ must all be equal to zero. This means we need:

$$ \begin{align*}
    \alpha_1 + \alpha_3 &= 0, \\
    \alpha_1 + \alpha_2 &= 0, \\
    \alpha_1 - \alpha_2 - \alpha_3 &= 0.
\end{align*} $$

Solving this system using Gauss-Jordan elimination:

$$ \begin{align*}
    & \left( \begin{array}{ccc}
        1 & 0 & 1\\
        1 & 1 & 0\\
        1 & -1 & -1
    \end{array} \right)
    \\ \\
    \begin{matrix} R_2 - R_1 \\ R_3 - R_1 \end{matrix} \longrightarrow  &
    \left( \begin{array}{ccc}
        1 & 0 & 1\\
        0 & 1 & -1\\
        0 & -1 & -2
    \end{array} \right)
    \\ \\
    R_3 + R_2\longrightarrow  &
    \left( \begin{array}{ccc}
        1 & 0 & 1\\
        0 & 1 & -1\\
        0 & 0 & -3
    \end{array} \right)
	\\ \\
    -\frac{1}{3}R_3\longrightarrow &
    \left( \begin{array}{ccc}
        1 & 0 & 1\\
        0 & 1 & -1\\
        0 & 0 & 1
    \end{array} \right)
    \\ \\
    \begin{matrix} R_1 - R_3 \\ R_2 + R_3 \end{matrix}\longrightarrow  &
    \left( \begin{array}{ccc}
        1 & 0 & 0\\
        0 & 1 & 0\\
        0 & 0 & 1
    \end{array} \right)
\end{align*} $$

Therefore the only solution is $\alpha_1 = \alpha_2 = \alpha_3 = 0$, which means the polynomials $u$, $v$ and $w$ are linearly independent.
```
